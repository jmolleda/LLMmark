ollama:
  host: "http://localhost:11434/"

ollama_models:
  - display_name: "DeepSeek R1:1.5b"
    model_id: "deepseek-r1:1.5b"      # 1.1 GB
  - display_name: "Gemma3:1b"
    model_id: "gemma3:1b"             # 815 MB
  - display_name: "Gemma3:4b"
    model_id: "gemma3:4b"             # 3.1 GB
  - display_name: "Gemma3n:e2b"
    model_id: "gemma3n:e2b"            # 5.6 GB
  - display_name: "Gemma3n:e4b"
    model_id: "gemma3n:e4b"            # 7.5 GB
  - display_name: "Llama3.2:1b"
    model_id: "llama3.2:1b"           # 1.3 GB
  - display_name: "Moondream 2"
    model_id: "moondream:1.8b"        # 1.7 GB
  - display_name: "smollm2:1.7b"
    model_id: "smollm2:1.7b"          # 1.8 GB
  - display_name: "TinyLlama:1.1b"
    model_id: "tinyllama:1.1b"        # 638 MB
  - display_name: "Qwen3:0.6b"
    model_id: "qwen3:0.6b"            # 523 MB
  - display_name: "Qwen3:1.7b"
    model_id: "qwen3:1.7b"            # 1.6 GB
  - display_name: "Qwen3:4b"
    model_id: "qwen3:4b"              # 3.8 GB

openai_models:
  - display_name: "GPT-3.5 Turbo"
    model_id: "gpt-3.5-turbo"
    base_url: "https://api.openai.com/v1/"
    api_key: "OPENAI_API_KEY"
    max_requests_per_minute: 0
  - display_name: "GPT-4.1"
    model_id: "gpt-4.1"
    base_url: "https://api.openai.com/v1/"
    api_key: "OPENAI_API_KEY"
    max_requests_per_minute: 0
  - display_name: "Gemini 2.0 Flash"
    model_id: "gemini-2.0-flash"
    base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    api_key: "GEMINI_API_KEY"
    max_requests_per_minute: 15

# Valid question_types:
question_types: 
  - open_answer: "Open Answer"
  - multiple_choice: "Multiple Choice"

# Default question type
question_type: "open_answer"

# Valid model modes
# - chat
# - generate
model_mode: "chat"

folders:
  data_folder_name: "../data/questions"
  base_experiments_folder: "../data/runs"
  experiment_folder_name: "run_"

files:
  question_file_name: "question_"
  question_file_extension: ".txt"
  stats_file_name: "stats.json"

num_runs_per_question: 10

experiments_folder: "../data/runs"
question_file_prefix: "question_"
api_key_env_var: "OPENAI_API_KEY"
model_name: "gemini-2.0-flash"

# en: English and es: Spanish
language: "en"

# Valid prompting techniques:
prompting_techniques:
  - S1: "Standard, Zero-shot and Task-Oriented"
  - S2: "Standard, Zero-shot and Role-Oriented"
  - S3: "Standard, Few-shot and Task-Oriented"
  - S4: "Standard, Few-shot and Role-Oriented"
  - R1: "Reasoning, Zero-shot and Task-Oriented"
  - R2: "Reasoning, Zero-shot and Role-Oriented"
  - R3: "Reasoning, Few-shot and Role-Oriented"
  - R4: "Reasoning, Few-shot and Task-Oriented"
  - D1: "Definition-based, Zero-shot and Task-Oriented"
  - D2: "Definition-based, Zero-shot and Role-Oriented"
  - D3: "Definition-based, Few-shot and Task-Oriented"
  - D4: "Definition-based, Few-shot and Role-Oriented"

prompting_technique: "R1"

few_shot_examples_file: "few_shot_examples.yaml"

information_file: "information.yaml"

context_chapters_path: "../data/context/book/chapters"

temperature: 0.0
top_p: 0.1

evaluation_output_file: "evaluation_output.json"
evaluation:
  judge_model: "gemini/gemini-1.5-flash-latest"