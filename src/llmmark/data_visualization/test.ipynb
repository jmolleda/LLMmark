{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60e3d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Optional, Callable\n",
    "from opik import Opik\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "SENTENCE_TRANSFORMER_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "OPIK_DETERMINISM_PROJECT_NAME = \"LLMmark_determinism\"\n",
    "\n",
    "EMPTY_PLACEHOLDER = '_EMPTY_FAILURE_'\n",
    "TIMEOUT_PLACEHOLDER = '_TIMEOUT_FAILURE_'\n",
    "OVERTHINK_PLACEHOLDER = '_OVERTHINK_FAILURE_'\n",
    "BAD_FORMAT_PLACEHOLDER = '_FORMAT_FAILURE_'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1175d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_identify_failures(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies failed responses in the DataFrame based on timeout or token limit.\n",
    "    \"\"\"\n",
    "    timeout = 120\n",
    "    \n",
    "    is_empty = df['span_output_raw_answer'].fillna('').str.strip() == ''\n",
    "    \n",
    "    # It is considered timeout if the response time is > 120 seconds and the answer is empty\n",
    "    # Some models like gemma3n can take more than 120 seconds because of the memory limit (we use swap memory)\n",
    "    is_timeout = (df['response_time'] >= timeout).fillna(False) & is_empty\n",
    "    \n",
    "    \n",
    "    # If the raw_answer contains <think>, we consider that it has reached the token limit or an infinite loop\n",
    "    is_token_limit_hit = df['span_output_raw_answer'].str.contains('<think>', na=False)\n",
    "    \n",
    "    df['is_failure'] = is_timeout | is_token_limit_hit | is_empty\n",
    "    \n",
    "    conditions = [\n",
    "        is_timeout,\n",
    "        is_token_limit_hit,\n",
    "        is_empty\n",
    "    ]\n",
    "    \n",
    "    placeholders = [\n",
    "        TIMEOUT_PLACEHOLDER,\n",
    "        OVERTHINK_PLACEHOLDER,\n",
    "        EMPTY_PLACEHOLDER\n",
    "    ]\n",
    "    \n",
    "    # Apply the failure placeholders in the answer column, else keep the original raw answer\n",
    "    df['answer'] = np.select(conditions, placeholders, default=df['span_output_raw_answer'])\n",
    "\n",
    "    failure_count = df['is_failure'].sum()\n",
    "    if failure_count > 0:\n",
    "        print(f\"INFO: Total of {failure_count} failed responses (timeout, empty answer or infinite loop).\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_model_info(model_name: str, tags: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Parses model ID, display name, and size from the model name and tags.\n",
    "    Adjust this function based on your actual model naming conventions.\n",
    "    \"\"\"\n",
    "    model_id = model_name\n",
    "    model_size = \"N/A\"\n",
    "    question_type = \"N/A\"\n",
    "\n",
    "    match = re.search(r':([\\d\\.]+)b', model_name)\n",
    "    if match:\n",
    "        model_size = match.group(1) + \"B\"\n",
    "\n",
    "    if \"multiple_choice\" in tags:\n",
    "        question_type = \"multiple_choice\"\n",
    "    elif \"open_answer\" in tags:\n",
    "        question_type = \"open_answer\"\n",
    "\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"model_size\": model_size,\n",
    "        \"question_type\": question_type\n",
    "    }\n",
    "\n",
    "def get_opik_flat_data_for_csv(project_name: str = OPIK_DETERMINISM_PROJECT_NAME) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetches detailed trace and span data from Opik and flattens it for CSV export.\n",
    "    Each dictionary in the returned list represents a single span,\n",
    "    including its parent trace's metadata.\n",
    "    \"\"\"\n",
    "    client = Opik()\n",
    "    flat_data = []\n",
    "\n",
    "    print(f\"Fetching traces from project: {project_name}...\")\n",
    "\n",
    "    traces = client.search_traces(\n",
    "        project_name=project_name,\n",
    "        max_results=25000\n",
    "    )\n",
    "\n",
    "    if not traces:\n",
    "        print(f\"No traces found in project '{project_name}'. Please check the project name and your Opik configuration.\")\n",
    "        return []\n",
    "    \n",
    "    # Delete traces with None values\n",
    "    traces = [trace for trace in traces if trace.name is not None]\n",
    "\n",
    "    for i, trace in enumerate(traces):\n",
    "        \n",
    "        print(f\"Processing trace {i+1}/{len(traces)}: {trace.name} ({trace.id})\")\n",
    "\n",
    "        trace_content = client.get_trace_content(trace.id)\n",
    "        spans = client.search_spans(project_name=project_name, trace_id=trace.id)\n",
    "\n",
    "        if not spans:\n",
    "            print(f\"  No spans found for trace {trace.id}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        model_info = parse_model_info(trace.name, trace.tags)\n",
    "        \n",
    "        model_source = \"N/A\"\n",
    "        if \"local\" in trace.tags:\n",
    "            model_source = \"local\"\n",
    "        elif \"online\" in trace.tags:\n",
    "            model_source = \"online\"\n",
    "\n",
    "        trace_flat_metadata = {\n",
    "            \"trace_id\": trace.id,\n",
    "            \"run_name\": trace.name,\n",
    "            \"model_display_name\": trace_content.metadata.get(\"model_display_name\"),\n",
    "            \"language\": trace_content.metadata.get(\"language\", \"en\"),\n",
    "            \"prompting_tech\": trace_content.metadata.get(\"prompting_tech\", \"N/A\"),\n",
    "            \"num_runs_per_question\": trace_content.metadata.get(\"num_runs_per_question\", 1),\n",
    "            \"model_source\": model_source,\n",
    "            \"temperature\": trace_content.metadata.get(\"temperature\", \"N/A\"),\n",
    "            \"top_p\": trace_content.metadata.get(\"top_p\", 0.1),\n",
    "            \"exercise\": trace_content.metadata.get(\"exercise\", \"N/A\"),\n",
    "            \"question_type\": model_info[\"question_type\"],\n",
    "            **{f\"trace_meta_{k.replace('.', '_')}\": v for k, v in trace_content.metadata.items() # Replace '.' in keys for valid column names\n",
    "            if k not in [\"language\", \"prompting_tech\", \"num_runs_per_question\", \n",
    "                         \"model_source\", \"temperature\", \"top_p\", \"exercise\", \n",
    "                         \"prompt_tech\", \"question_type\", \"comments\", \"model_id\", \"model_display_name\", \"top-p\", \"run_name\"]}\n",
    "        }\n",
    "\n",
    "        # Process each span and combine with trace-level metadata\n",
    "        for j, span in enumerate(spans):\n",
    "            span_response_time = span.output.get(\"response_time (s)\", \"N/A\")\n",
    "\n",
    "            span_input_question = span.input.get(\"question\", str(span.input)) if isinstance(span.input, dict) else str(span.input)\n",
    "            span_output_answer = span.output.get(\"answer\", str(span.output)) if isinstance(span.output, dict) else str(span.output)\n",
    "            span_output_raw_answer = span.output.get(\"raw_answer\", span_output_answer) if isinstance(span.output, dict) else span_output_answer\n",
    "\n",
    "            correct_answer = span.metadata.get(\"correct_answer\", \"PLACEHOLDER_CORRECT_ANSWER\")\n",
    "            \n",
    "            \n",
    "            span_usage = span.usage or {} # Usamos un diccionario vacÃ­o si 'usage' es None\n",
    "            completion_tokens = span_usage.get(\"completion_tokens\", 0)\n",
    "\n",
    "            span_data_row = {\n",
    "                \"span_id\": span.id,\n",
    "                \"span_name\": span.name,\n",
    "                \"response_time\": span_response_time,\n",
    "                \"span_input_question\": span_input_question,\n",
    "                \"span_output_answer\": span_output_answer,\n",
    "                \"span_output_raw_answer\": span_output_raw_answer,\n",
    "                \"span_correct_answer\": correct_answer,\n",
    "                \"completion_tokens\": completion_tokens,\n",
    "                \"question_file\": span.metadata.get(\"question_file\", \"N/A\"),\n",
    "            }\n",
    "            \n",
    "            combined_row = {**span_data_row, **trace_flat_metadata}\n",
    "            flat_data.append(combined_row)\n",
    "\n",
    "    return flat_data\n",
    "\n",
    "def filter_and_save_dataframe(\n",
    "    df: pd.DataFrame, \n",
    "    csv_filename: str = \"opik_determinism_data.csv\", \n",
    "    temperature_filter: Optional[float] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Filters an existing DataFrame by temperature and saves it to a CSV file.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"\\nInput DataFrame is empty. No CSV file will be created.\")\n",
    "        return\n",
    "\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    print(\"DataFrame after preprocessing:\")\n",
    "    print(filtered_df.head())\n",
    "\n",
    "    if temperature_filter is not None:\n",
    "        filtered_df['temperature'] = pd.to_numeric(filtered_df['temperature'], errors='coerce')\n",
    "        filtered_df = filtered_df[filtered_df['temperature'] == temperature_filter].copy()\n",
    "        print(f\"\\nFiltered DataFrame for temperature = {temperature_filter}:\")\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f\"No data after filtering for temperature = {temperature_filter}.\")\n",
    "        return\n",
    "\n",
    "    output_filename = csv_filename\n",
    "    output_dir = '../../../data/determinism'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    filtered_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"DataFrame head:\")\n",
    "    print(filtered_df.head())\n",
    "    print(f\"\\nDataFrame shape: {filtered_df.shape}\")\n",
    "\n",
    "    print(f\"\\nSuccessfully extracted data and saved to {output_path}\")\n",
    "      \n",
    "def get_dataframe_from_csv(csv_filename: str = \"opik_determinism_data.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a DataFrame.\n",
    "    \"\"\"\n",
    "    output_dir = '../../../data/determinism'\n",
    "    output_path = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"CSV file {output_path} does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(output_path, encoding='utf-8')\n",
    "    print(f\"DataFrame loaded from {output_path} with shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analyse multiple_choice answers\n",
    "# def calculate_determinism_mc(answers):\n",
    "#     \"\"\"Calculates the determinism of a list of answers (multiple choice).\n",
    "\n",
    "#     Args:\n",
    "#         answers (list): A list of answers to evaluate.\n",
    "\n",
    "#     Returns:\n",
    "#         float: The number of most frequent answer.\n",
    "#     \"\"\"\n",
    "#     unique_answers = set(answers)\n",
    "\n",
    "#     if len(unique_answers) == 1:\n",
    "#         return len(answers)  # Completely deterministic\n",
    "#     else:\n",
    "#         # Calculate the proportion of the most frequent answer\n",
    "#         counter = Counter(answers)\n",
    "#         most_frequent_answer = counter.most_common(1)[0][1]\n",
    "#         return most_frequent_answer\n",
    "\n",
    "def extract_answer_letter_mc(answer_text: str) -> Optional[str]: \n",
    "    \"\"\"\n",
    "    Extracts the answer letter from the given text.\n",
    "    The expected format is: [a]\n",
    "    If multiple bracketed letters follow, only the last one is returned.\n",
    "    \"\"\"\n",
    "    try:       \n",
    "        all_matches = re.findall(r'\\[([a-zA-Z])\\]', answer_text)\n",
    "        if all_matches:\n",
    "            # Return the last match found\n",
    "            return all_matches[-1]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error extracting answer letter: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# def calculate_determinism_oa(answers: List[str], umbral=0.8) -> float:\n",
    "#     \"\"\"Calculate the determinism of open answer questions.\n",
    "\n",
    "#     Args:\n",
    "#         answers (List[str]): The list of answers to evaluate.\n",
    "#         umbral (float, optional): The similarity threshold for considering answers as similar. Defaults to 0.8.\n",
    "\n",
    "#     Returns:\n",
    "#         float: The determinism score between 0 and 1.\n",
    "#     \"\"\"\n",
    "#     if not answers:\n",
    "#         return 0.0  # No answers, no determinism\n",
    "\n",
    "#     cleaned_answers = [str(ans) if pd.notna(ans) else '' for ans in answers]\n",
    "    \n",
    "#     # Remove failure answers\n",
    "#     cleaned_answers = [ans for ans in cleaned_answers if ans != '_GENERATION_FAILURE_']\n",
    "    \n",
    "    # if len(cleaned_answers) < 2:\n",
    "    #     return 0.0\n",
    "     \n",
    "    # embeddings = SENTENCE_TRANSFORMER_MODEL.encode(cleaned_answers)\n",
    "\n",
    "    # similarities = []\n",
    "    # for i in range(len(cleaned_answers)):\n",
    "    #     for j in range(i+1, len(cleaned_answers)):\n",
    "    #         sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "    #         similarities.append(sim)\n",
    "\n",
    "    # return np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def get_answer_consistency(answers: List[str], num_successful) -> float:\n",
    "    \"\"\"Calculates the determinism of a list of answers (multiple choice).\n",
    "\n",
    "    Args:\n",
    "        answers (list): A list of answers to evaluate.\n",
    "        num_successful (int): The number of successful runs (non-failure answers).\n",
    "\n",
    "    Returns:\n",
    "        float: The consistency score between 0.0 and 1.0\n",
    "    \"\"\"\n",
    "    unique_answers = set(answers)\n",
    "\n",
    "    if len(unique_answers) == 1:\n",
    "        return 1.0  # Completely deterministic\n",
    "    else:\n",
    "        if num_successful == 0:\n",
    "            return 0.0\n",
    "        num_successful = num_successful\n",
    "        # Calculate the proportion of the most frequent answer\n",
    "        counter = Counter(answers)\n",
    "        most_frequent_answer = counter.most_common(1)[0][1]\n",
    "        consistency = most_frequent_answer / num_successful\n",
    "            \n",
    "        return round(consistency, 2)\n",
    "\n",
    "\n",
    "def get_reasoning_consistency(reasonings: List[str]) -> float:\n",
    "    if not reasonings:\n",
    "        return 0.0  # No reasonings, no determinism\n",
    "\n",
    "    cleaned_reasonings = [str(r) if pd.notna(r) else '' for r in reasonings]\n",
    "\n",
    "    # Remove failure answers\n",
    "    cleaned_reasonings = [r for r in cleaned_reasonings if r != '_GENERATION_FAILURE_']\n",
    "\n",
    "    if len(cleaned_reasonings) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    embeddings = SENTENCE_TRANSFORMER_MODEL.encode(cleaned_reasonings)\n",
    "\n",
    "    similarities = []\n",
    "    for i in range(len(cleaned_reasonings)):\n",
    "        for j in range(i+1, len(cleaned_reasonings)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "            similarities.append(sim)\n",
    "\n",
    "    consistency = np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "    return round(consistency, 2)\n",
    "\n",
    "def calculate_consistency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Ponderations of the consistency\n",
    "    answer_weight = 0.7\n",
    "    reasoning_weight = 0.3\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    required_columns = ['model_display_name', 'question_file', 'prompting_tech', 'answer', 'is_failure', 'final_answer', 'reasoning']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        missing = [col for col in required_columns if col not in df.columns]\n",
    "        raise ValueError(f\"The DataFrame does not have the columns: {required_columns}. Missing: {missing}\")\n",
    "\n",
    "    grouping_keys = ['model_display_name', 'question_file', 'prompting_tech']\n",
    "    df_grouped = df.groupby(grouping_keys)\n",
    "\n",
    "    for group_id, group in df_grouped:        \n",
    "        all_answers = group['answer'].tolist()\n",
    "        successful_answers = group.loc[~group['is_failure'], 'answer'].tolist()\n",
    "        final_answers = group['final_answer'].tolist()\n",
    "        reasonings = group['reasoning'].tolist()\n",
    "        num_total_runs = len(group)\n",
    "        num_failures = group['is_failure'].value_counts().get(True, 0)\n",
    "        num_successful = num_total_runs - num_failures\n",
    "\n",
    "        \n",
    "        if (num_successful == 0):\n",
    "            print(f\"No successful runs for group {group_id}\")\n",
    "            consistency = 0.0\n",
    "        else:\n",
    "            answer_consistency = get_answer_consistency(successful_answers, num_successful)\n",
    "            print(\"---- CONSISTENCY ANSWER: \", answer_consistency)\n",
    "            reasoning_consistency = get_reasoning_consistency(reasonings)\n",
    "            print(\"---- CONSISTENCY REASONING: \", reasoning_consistency)\n",
    "\n",
    "            consistency = round((answer_consistency * answer_weight) + (reasoning_consistency * reasoning_weight), 2)\n",
    "\n",
    "\n",
    "        results_list.append({\n",
    "            'Model Display Name': group_id[0],\n",
    "            'Question File': group_id[1],\n",
    "            'Prompting Tech': group_id[2],\n",
    "            'Consistency Score': consistency,\n",
    "            'Answer Consistency': answer_consistency,\n",
    "            'Reasoning Consistency': reasoning_consistency,\n",
    "            'Number of Runs': num_total_runs,\n",
    "            'Number of Failures': num_failures,\n",
    "            'Number of Successful Runs': num_successful,\n",
    "            'Final Answer': final_answers,\n",
    "            'Reasoning': reasonings,\n",
    "            'All Answers': all_answers,\n",
    "        })\n",
    "        \n",
    "    if not results_list:\n",
    "        print(\"No determinism results found. The input DataFrame may be empty or not contain valid data.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    results_df = results_df.sort_values(by=['Model Display Name', 'Question File', 'Prompting Tech']).reset_index(drop=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def get_determinism(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    determinism_df = df.copy()\n",
    "    determinism_df['Determinism'] = determinism_df['Consistency Score'].apply(lambda x: True if x >= 0.8 else False)\n",
    "    return determinism_df\n",
    "\n",
    "\n",
    "def create_determinism_table(df, filename=\"determinism_summary_table.csv\"):\n",
    "    \"\"\"Creates a summary table of determinism scores and saves it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing LLM experiment results.\n",
    "        filename (str, optional): The name of the output CSV file. Defaults to \"determinism_summary_table.csv\".\n",
    "    \"\"\"\n",
    "    print(f\"\\nColumns in {df}:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    df = df.sort_values(by=['model_display_name', 'question_file', 'prompting_tech'])\n",
    "    \n",
    "    \n",
    "    # Calculate consistency\n",
    "    consistency_df = calculate_consistency(df)\n",
    "\n",
    "    determinism_df = get_determinism(consistency_df)  \n",
    "\n",
    "\n",
    "    #determinism_table = process_determinism_and_store(consistency_df, function)\n",
    "\n",
    "    print(\"\\n--- Determinism Results Table ---\")\n",
    "    print(determinism_df)\n",
    "    \n",
    "    # Save the determinism table to a CSV file\n",
    "    output_dir_tables = '../../../data/determinism_tables'\n",
    "    os.makedirs(output_dir_tables, exist_ok=True)\n",
    "    table_filepath = os.path.join(output_dir_tables, filename)\n",
    "    determinism_df.to_csv(table_filepath, index=False, float_format='%.2f')\n",
    "    print(f\"\\nDeterminism table saved to: {table_filepath}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def extract_reasoning(answer_text: str) -> str:\n",
    "    if not isinstance(answer_text, str):\n",
    "        return None\n",
    "    match_1 = re.search(r\"\\[\\[ ## thought ## \\]\\](.*?)\\[\\[ ## answer ## \\]\\]\", answer_text, re.DOTALL)\n",
    "    \n",
    "    match_2 = re.search(r\"\\[\\[ ## thought ## \\]\\](.*?)\\[\\[ ## completed ## \\]\\]\", answer_text, re.DOTALL)\n",
    "\n",
    "    if match_1:\n",
    "        return match_1.group(1).strip()\n",
    "    elif match_2:\n",
    "        return match_2.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_determinism_table_mc(mc_df, filename):\n",
    "    \"\"\"Generates a determinism table for multiple choice questions.\n",
    "\n",
    "    Args:\n",
    "        mc_df (pd.DataFrame): DataFrame containing multiple choice question data.\n",
    "        filename (str): Name of the output CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    mc_df = mc_df[mc_df['question_type'] == 'multiple_choice'].copy()\n",
    "    mc_df['span_output_raw_answer'] = mc_df['span_output_raw_answer'].fillna(EMPTY_PLACEHOLDER)\n",
    "\n",
    "    # Extract the answer letter from multiple choice answers\n",
    "    mc_df['final_answer'] = mc_df['span_output_raw_answer'].apply(extract_answer_letter_mc)\n",
    "    mc_df['final_answer'] = mc_df['final_answer'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    # Extract reasoning from the answer\n",
    "    mc_df['reasoning'] = mc_df['span_output_raw_answer'].apply(extract_reasoning)\n",
    "    mc_df['reasoning'] = mc_df['reasoning'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    \n",
    "    \n",
    "\n",
    "    # If final_answer or reasoning is None, we set placeholder value for the answer and is_failure to True\n",
    "    mc_df['final_answer'] = mc_df['final_answer'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    mc_df['reasoning'] = mc_df['reasoning'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "\n",
    "\n",
    "    mc_df['is_failure'] = mc_df['final_answer'].str.contains(BAD_FORMAT_PLACEHOLDER) | mc_df['reasoning'].str.contains(BAD_FORMAT_PLACEHOLDER) | mc_df['span_output_raw_answer'].str.contains(EMPTY_PLACEHOLDER)\n",
    "    \n",
    "\n",
    "    # Rename span_correct_answer to correct_answer\n",
    "    mc_df.rename(columns={'span_correct_answer': 'correct_answer'}, inplace=True)\n",
    "    # Drop all columns except run_name, question_file, answer, correct_answer, promtpting_tech\n",
    "    mc_df = mc_df[['run_name', 'model_display_name', 'question_file', 'answer', 'correct_answer', 'prompting_tech', 'is_failure', 'reasoning', 'final_answer']]\n",
    "\n",
    "    # Order by question_file\n",
    "    mc_df = mc_df.sort_values(by=['question_file', 'answer']).reset_index(drop=True)\n",
    "\n",
    "    mc_df.head(5).style.set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('background-color', '#f2f2f2'), ('color', 'black')]}]\n",
    "    ).set_properties(**{'text-align': 'center'})\n",
    "    \n",
    "    \n",
    "    # Get unique model_display_name values\n",
    "    unique_models = mc_df['model_display_name'].unique()\n",
    "    print(\"MODELS: \", unique_models)\n",
    "    \n",
    "    # Create CSV determinism table\n",
    "    create_determinism_table(mc_df, filename=filename)\n",
    "\n",
    "\n",
    "\n",
    "def extract_answer(answer_text: str) -> Optional[str]:\n",
    "    if not isinstance(answer_text, str):\n",
    "        return None\n",
    "    match = re.search(r\"\\[\\[ ## answer ## \\]\\](.*?)\\[\\[ ## completed ## \\]\\]\", answer_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_determinism_table_oa(oa_df, filename):\n",
    "    \"\"\"Generates a determinism table for multiple choice questions.\n",
    "\n",
    "    Args:\n",
    "        oa_df (pd.DataFrame): DataFrame containing open answer question data.\n",
    "        filename (str): Name of the output CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    oa_df = oa_df[oa_df['question_type'] == 'multiple_choice'].copy()\n",
    "    oa_df['span_output_raw_answer'] = oa_df['span_output_raw_answer'].fillna(EMPTY_PLACEHOLDER)\n",
    "\n",
    "    # Extract the answer letter from multiple choice answers\n",
    "    oa_df['final_answer'] = oa_df['span_output_raw_answer'].apply(extract_answer)\n",
    "    oa_df['final_answer'] = oa_df['final_answer'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    # Extract reasoning from the answer\n",
    "    oa_df['reasoning'] = oa_df['span_output_raw_answer'].apply(extract_reasoning)\n",
    "    oa_df['reasoning'] = oa_df['reasoning'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    \n",
    "    \n",
    "\n",
    "    # If final_answer or reasoning is None, we set placeholder value for the answer and is_failure to True\n",
    "    oa_df['final_answer'] = oa_df['final_answer'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "    oa_df['reasoning'] = oa_df['reasoning'].fillna(BAD_FORMAT_PLACEHOLDER)\n",
    "\n",
    "\n",
    "    oa_df['is_failure'] = oa_df['final_answer'].str.contains(BAD_FORMAT_PLACEHOLDER) | oa_df['reasoning'].str.contains(BAD_FORMAT_PLACEHOLDER) | oa_df['span_output_raw_answer'].str.contains(EMPTY_PLACEHOLDER)\n",
    "    \n",
    "\n",
    "    # Rename span_correct_answer to correct_answer\n",
    "    oa_df.rename(columns={'span_correct_answer': 'correct_answer'}, inplace=True)\n",
    "    # Drop all columns except run_name, question_file, answer, correct_answer, promtpting_tech\n",
    "    oa_df = oa_df[['run_name', 'model_display_name', 'question_file', 'answer', 'correct_answer', 'prompting_tech', 'is_failure', 'reasoning', 'final_answer']]\n",
    "\n",
    "    # Order by question_file\n",
    "    oa_df = oa_df.sort_values(by=['question_file', 'answer']).reset_index(drop=True)\n",
    "\n",
    "    oa_df.head(5).style.set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('background-color', '#f2f2f2'), ('color', 'black')]}]\n",
    "    ).set_properties(**{'text-align': 'center'})\n",
    "    \n",
    "    \n",
    "    # Get unique model_display_name values\n",
    "    unique_models = oa_df['model_display_name'].unique()\n",
    "    print(\"MODELS: \", unique_models)\n",
    "    \n",
    "    # Create CSV determinism table\n",
    "    create_determinism_table(oa_df, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faf20d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces from project: LLMmark_determinism...\n",
      "Processing trace 1/288: run_111_gemma3n:e2b_0.4 (0197ca15-127b-7a01-8d4c-721291544b29)\n",
      "Processing trace 2/288: run_110_gemma3n:e2b_0.4 (0197ca14-e0b1-74c8-861b-497115583759)\n",
      "Processing trace 3/288: run_107_gemma3n:e4b_0.4 (0197c897-fcad-7201-9f47-592282552cb7)\n",
      "Processing trace 4/288: run_106_gemma3n:e2b_0.2 (0197c883-02b8-75d4-94ab-027f86e69f2d)\n",
      "Processing trace 5/288: run_105_gemma3n:e4b_0.2 (0197c87c-478e-7e8a-a0d9-d2ccce1d212a)\n",
      "Processing trace 6/288: run_104_gemma3n:e2b_0.2 (0197c876-914d-7210-9695-db54c5c33e76)\n",
      "Processing trace 7/288: run_103_gemma3n:e4b_0.4 (0197c86e-85d2-770b-83bd-ad742844aed7)\n",
      "Processing trace 8/288: run_102_gemma3n:e4b_0.0 (0197c861-b223-75f6-9e6b-e9cdd55da5a7)\n",
      "Processing trace 9/288: run_101_gemma3n:e2b_0.0 (0197c860-6fb5-736e-ab27-4f6e93f67394)\n",
      "Processing trace 10/288: run_100_gemma3n:e4b_0.2 (0197c856-ab53-7813-a800-d6de5bb6ebac)\n",
      "Processing trace 11/288: run_099_gemma3n:e2b_0.0 (0197c855-f92f-7077-aebd-35923790ad27)\n",
      "Processing trace 12/288: run_098_gemma3n:e4b_0.4 (0197c83c-35dc-7584-b58a-828db17343c7)\n",
      "Processing trace 13/288: run_097_gemma3n:e4b_0.0 (0197c83b-ab55-705b-82d3-e2119d5640d1)\n",
      "Processing trace 14/288: run_096_gemma3n:e2b_0.4 (0197c839-3989-7be2-82a8-29004ce5814d)\n",
      "Processing trace 15/288: run_095_gemma3n:e2b_0.4 (0197c833-c9ff-7b6b-aca2-34a28b96d4ca)\n",
      "Processing trace 16/288: run_094_gemma3n:e4b_0.4 (0197c822-7764-7ba4-8770-d8caeba8ac6c)\n",
      "Processing trace 17/288: run_093_gemma3n:e4b_0.2 (0197c817-0797-75f7-a8ad-d10292d3917b)\n",
      "Processing trace 18/288: run_092_gemma3n:e2b_0.2 (0197c810-6915-708c-9cd7-fca5fe5b87ff)\n",
      "Processing trace 19/288: run_091_gemma3n:e2b_0.2 (0197c80f-8c8b-72d7-82bb-85cce88d8c30)\n",
      "Processing trace 20/288: run_090_gemma3n:e4b_0.2 (0197c809-1c95-7a21-bce7-bdd214ef08c1)\n",
      "Processing trace 21/288: run_089_gemma3n:e4b_0.0 (0197c7ec-afcd-7135-86de-f23e258ce41a)\n",
      "Processing trace 22/288: run_088_gemma3n:e4b_0.0 (0197c7ec-8fd8-7c5c-8ba8-d58c45a02c33)\n",
      "Processing trace 23/288: run_087_gemma3n:e2b_0.0 (0197c7ec-6a4e-7f80-8962-67cdced58662)\n",
      "Processing trace 24/288: run_086_gemma3n:e2b_0.0 (0197c7ec-34f8-745f-a54a-004a89d73c57)\n",
      "Processing trace 25/288: run_085_gemma3n:e2b_0.4 (0197c72f-b1b8-7b51-bb09-9a2e85d88c98)\n",
      "Processing trace 26/288: run_084_gemma3n:e2b_0.4 (0197c72f-00db-7f39-9025-352fe5512e71)\n",
      "Processing trace 27/288: run_083_gemma3n:e2b_0.4 (0197c72b-ec6b-7048-b043-b508f03ded40)\n",
      "Processing trace 28/288: run_082_gemma3n:e2b_0.4 (0197c72b-0391-77db-b4dc-e36aa68709d1)\n",
      "Processing trace 29/288: run_081_gemma3n:e2b_0.2 (0197c708-7501-7568-8a22-a146c0391e83)\n",
      "Processing trace 30/288: run_080_gemma3n:e2b_0.2 (0197c708-711a-7340-a9b7-6f2767caaddf)\n",
      "Processing trace 31/288: run_079_gemma3n:e2b_0.2 (0197c705-afe6-730d-a7e4-fe53f1f3cb71)\n",
      "Processing trace 32/288: run_078_gemma3n:e2b_0.2 (0197c705-a891-7498-a50e-fcfc591d0f74)\n",
      "Processing trace 33/288: run_077_gemma3n:e2b_0.0 (0197c6e2-c9bc-78a0-bd9a-bb17f5e0b314)\n",
      "Processing trace 34/288: run_076_gemma3n:e2b_0.0 (0197c6e2-a701-735b-94f4-fff25825e83c)\n",
      "Processing trace 35/288: run_075_gemma3n:e2b_0.0 (0197c6e2-7e62-703f-a409-f62b18238c86)\n",
      "Processing trace 36/288: run_074_gemma3n:e2b_0.0 (0197c6e2-61ae-7488-8fb2-d8ef9f6fd29a)\n",
      "Processing trace 37/288: run_073_gemma3n:e4b_0.4 (0197c697-583d-72c6-8029-93e2263192ea)\n",
      "Processing trace 38/288: run_072_gemma3n:e4b_0.4 (0197c692-2a7c-796d-baff-f4bfdf5a8b8b)\n",
      "Processing trace 39/288: run_071_gemma3n:e4b_0.4 (0197c690-ee47-7815-ac7c-3c4a2008ea12)\n",
      "Processing trace 40/288: run_070_gemma3n:e4b_0.4 (0197c690-0af8-7fce-b3af-9a213bae1881)\n",
      "Processing trace 41/288: run_069_gemma3n:e4b_0.2 (0197c67e-eb03-7c24-90b6-e23015a975a6)\n",
      "Processing trace 42/288: run_068_gemma3n:e4b_0.2 (0197c67e-1142-74bc-87a6-30af8caf76e7)\n",
      "Processing trace 43/288: run_067_gemma3n:e4b_0.2 (0197c67c-a4f2-7f74-bc76-48110e1e2769)\n",
      "Processing trace 44/288: run_066_gemma3n:e4b_0.2 (0197c67c-8cad-7dfb-875e-2470e7d93ad6)\n",
      "Processing trace 45/288: run_065_gemma3n:e4b_0.0 (0197c668-f29a-73a4-8a71-5ed1bbf538a6)\n",
      "Processing trace 46/288: run_064_gemma3n:e4b_0.0 (0197c668-d33c-7e52-afc4-9334e64c4ce0)\n",
      "Processing trace 47/288: run_063_gemma3n:e4b_0.0 (0197c668-b2d9-7722-81d7-7a27a91973a5)\n",
      "Processing trace 48/288: run_062_gemma3n:e4b_0.0 (0197c668-8255-7bc3-99bd-bc3d7e82b1f6)\n",
      "Processing trace 49/288: run_049_qwen3:4b_0.2 (0197c174-ebcd-7404-97e0-3ba8fa383e50)\n",
      "Processing trace 50/288: run_049_qwen3:1.7b_0.2 (0197c16b-ebc8-7aa4-b737-d650e97f8916)\n",
      "Processing trace 51/288: run_049_qwen3:0.6b_0.2 (0197c15a-d25e-7881-a4db-21d293f536fe)\n",
      "Processing trace 52/288: run_048_qwen3:4b_0.2 (0197c14f-4be2-7d1e-86e4-743f7c49f93f)\n",
      "Processing trace 53/288: run_049_tinyllama:1.1b_0.2 (0197c14e-44f1-71ef-a8ab-255f8f776f5a)\n",
      "Processing trace 54/288: run_049_smollm2:1.7b_0.2 (0197c14a-40af-7385-a226-2c9b9ed9d809)\n",
      "Processing trace 55/288: run_049_moondream:1.8b_0.2 (0197c14a-309e-7ec8-a55c-c27e6b230250)\n",
      "Processing trace 56/288: run_049_llama3.2:1b_0.2 (0197c147-32a1-76dc-b04c-d006dbd74b8b)\n",
      "Processing trace 57/288: run_048_qwen3:1.7b_0.2 (0197c13e-b877-729a-b73f-c6d6fd4cd48c)\n",
      "Processing trace 58/288: run_048_qwen3:0.6b_0.2 (0197c134-c8ae-7c68-a166-45961d80acd5)\n",
      "Processing trace 59/288: run_049_gemma3:4b_0.2 (0197c134-4202-76ce-9b06-2429467edb3a)\n",
      "Processing trace 60/288: run_048_tinyllama:1.1b_0.2 (0197c12e-2454-7390-9af5-65f1993273e0)\n",
      "Processing trace 61/288: run_049_gemma3:1b_0.2 (0197c12a-cee7-74bc-a40d-d36a5669c068)\n",
      "Processing trace 62/288: run_048_smollm2:1.7b_0.2 (0197c12a-7535-7c68-b46f-2b5658b3a6af)\n",
      "Processing trace 63/288: run_048_moondream:1.8b_0.2 (0197c12a-5b3a-78b6-8a8c-63cbddc9b05a)\n",
      "Processing trace 64/288: run_048_llama3.2:1b_0.2 (0197c127-76c0-7123-b1f9-2ebe63aea32a)\n",
      "Processing trace 65/288: run_048_gemma3:4b_0.2 (0197c116-68a1-7689-a43e-6a42473df4ff)\n",
      "Processing trace 66/288: run_049_deepseek-r1:1.5b_0.2 (0197c111-8fb6-767c-b2fc-c7d6204e5e8e)\n",
      "Processing trace 67/288: run_048_gemma3:1b_0.2 (0197c111-8578-7e4f-922c-d27cb092b8d8)\n",
      "Processing trace 68/288: run_047_qwen3:4b_0.0 (0197c0fe-279b-7341-8504-eaf89ee2bdf2)\n",
      "Processing trace 69/288: run_048_deepseek-r1:1.5b_0.2 (0197c0f3-d545-7bb2-a4a4-e3290ad5dc41)\n",
      "Processing trace 70/288: run_047_qwen3:1.7b_0.0 (0197c0eb-40a8-70db-bc99-2686e796cc14)\n",
      "Processing trace 71/288: run_046_qwen3:4b_0.0 (0197c0dd-d7f2-75eb-bd92-2572f9e850cc)\n",
      "Processing trace 72/288: run_047_qwen3:0.6b_0.0 (0197c0d7-3b32-7a36-baae-04748b1fde41)\n",
      "Processing trace 73/288: run_046_qwen3:1.7b_0.0 (0197c0d1-a2a7-7257-94cc-32ebe1ff6937)\n",
      "Processing trace 74/288: run_047_tinyllama:1.1b_0.0 (0197c0cf-34fc-7734-a6a1-4ba2d2244334)\n",
      "Processing trace 75/288: run_047_smollm2:1.7b_0.0 (0197c0cb-ec45-745b-a997-c1b7b43dfc64)\n",
      "Processing trace 76/288: run_047_moondream:1.8b_0.0 (0197c0cb-dee2-733f-9249-ac72b87c5909)\n",
      "Processing trace 77/288: run_046_qwen3:0.6b_0.0 (0197c0cb-42b0-781c-b5f6-caf091754121)\n",
      "Processing trace 78/288: run_047_llama3.2:1b_0.0 (0197c0c9-6d6a-7f70-8a12-5d7d3dca1acf)\n",
      "Processing trace 79/288: run_046_tinyllama:1.1b_0.0 (0197c0bf-cda7-7c1e-aaed-fc0d79517d6c)\n",
      "Processing trace 80/288: run_046_smollm2:1.7b_0.0 (0197c0ba-80ed-7528-a7b6-d47449a5d4f0)\n",
      "Processing trace 81/288: run_046_moondream:1.8b_0.0 (0197c0ba-5f16-74ba-b61f-ad011a2c05c0)\n",
      "Processing trace 82/288: run_047_gemma3:4b_0.0 (0197c0b6-9efd-79aa-bf99-8e5c071c0f50)\n",
      "Processing trace 83/288: run_046_llama3.2:1b_0.0 (0197c0b6-63d3-7fa4-9ad8-c0056ababbb7)\n",
      "Processing trace 84/288: run_047_gemma3:1b_0.0 (0197c0a8-0cde-74e6-9208-376070720765)\n",
      "Processing trace 85/288: run_046_gemma3:4b_0.0 (0197c0a5-b92c-7188-9872-4a22312d164f)\n",
      "Processing trace 86/288: run_046_gemma3:1b_0.0 (0197c0a0-9539-7b64-b06f-f94c4e01856e)\n",
      "Processing trace 87/288: run_047_deepseek-r1:1.5b_0.0 (0197c094-b5ff-7bae-b42d-fba8a7766214)\n",
      "Processing trace 88/288: run_046_deepseek-r1:1.5b_0.0 (0197c08b-a64e-79f5-b1d5-870b0d895f07)\n",
      "Processing trace 89/288: run_018_qwen3:4b_0.2 (0197c080-321d-7a4f-b939-00ace8052584)\n",
      "Processing trace 90/288: run_018_qwen3:1.7b_0.2 (0197c07c-b95a-7262-9268-d2eaf6824bce)\n",
      "Processing trace 91/288: run_017_qwen3:4b_0.2 (0197c074-474d-712f-acac-12d5e637c1ca)\n",
      "Processing trace 92/288: run_017_qwen3:1.7b_0.2 (0197c06a-3e69-7a9e-a171-6d79fa570304)\n",
      "Processing trace 93/288: run_018_qwen3:0.6b_0.2 (0197c06a-296d-768b-a863-bc6b8943fc6d)\n",
      "Processing trace 94/288: run_018_tinyllama:1.1b_0.2 (0197c065-2f7d-789d-bde2-b82516c82958)\n",
      "Processing trace 95/288: run_017_qwen3:0.6b_0.2 (0197c060-a3a7-7c8d-bd41-903541cc7e8b)\n",
      "Processing trace 96/288: run_017_tinyllama:1.1b_0.2 (0197c058-e0f4-71d1-aaa5-c30cf458cf61)\n",
      "Processing trace 97/288: run_018_smollm2:1.7b_0.2 (0197c057-fd1f-710d-9d7e-555860ae6798)\n",
      "Processing trace 98/288: run_018_moondream:1.8b_0.2 (0197c057-ef12-7e0a-8dfe-679ae34f73c2)\n",
      "Processing trace 99/288: run_018_llama3.2:1b_0.2 (0197c054-5f8f-7af5-aaf7-72acf79bf030)\n",
      "Processing trace 100/288: run_017_smollm2:1.7b_0.2 (0197c050-3303-76bd-914e-d75fb9ff0122)\n",
      "Processing trace 101/288: run_017_moondream:1.8b_0.2 (0197c050-144e-74c5-abb0-0581bb2b007c)\n",
      "Processing trace 102/288: run_017_llama3.2:1b_0.2 (0197c04b-89e9-7fd0-bd8f-aeb1f7e00869)\n",
      "Processing trace 103/288: run_018_gemma3:4b_0.2 (0197c044-67dd-76bb-842b-3dd2076d98d4)\n",
      "Processing trace 104/288: run_018_gemma3:1b_0.2 (0197c040-9b84-7f46-9f0b-ef03c054d2b8)\n",
      "Processing trace 105/288: run_017_gemma3:4b_0.2 (0197c03d-d8f7-7d02-b462-13b749e99236)\n",
      "Processing trace 106/288: run_017_gemma3:1b_0.2 (0197c039-8057-7c62-9a51-11dddaf4beeb)\n",
      "Processing trace 107/288: run_018_deepseek-r1:1.5b_0.2 (0197c02d-e812-7472-ae25-e47a1db85afb)\n",
      "Processing trace 108/288: run_017_deepseek-r1:1.5b_0.2 (0197c021-1dbf-79f3-b0fb-2e3e66a80a19)\n",
      "Processing trace 109/288: run_016_qwen3:4b_0.0 (0197c018-771c-7329-845a-3e6aa2f7b364)\n",
      "Processing trace 110/288: run_016_qwen3:1.7b_0.0 (0197c015-0121-75e2-a338-38c0120ba744)\n",
      "Processing trace 111/288: run_015_qwen3:4b_0.0 (0197c00a-5885-71ae-95aa-833c903a2235)\n",
      "Processing trace 112/288: run_016_qwen3:0.6b_0.0 (0197c001-fe14-7617-88de-0ef75c92d1c7)\n",
      "Processing trace 113/288: run_015_qwen3:1.7b_0.0 (0197c001-215c-7333-acb7-a4faa7e07f54)\n",
      "Processing trace 114/288: run_016_tinyllama:1.1b_0.0 (0197bffb-4eea-7d8b-bc21-68a467240211)\n",
      "Processing trace 115/288: run_016_smollm2:1.7b_0.0 (0197bff8-71b8-73ae-adad-010b2d6b9678)\n",
      "Processing trace 116/288: run_016_moondream:1.8b_0.0 (0197bff8-648d-79f4-9612-b8cdb27cb67b)\n",
      "Processing trace 117/288: run_015_qwen3:0.6b_0.0 (0197bff8-4d96-720d-bca0-80194049226e)\n",
      "Processing trace 118/288: run_016_llama3.2:1b_0.0 (0197bff6-11fc-7cc3-8da7-11e858a107d4)\n",
      "Processing trace 119/288: run_015_tinyllama:1.1b_0.0 (0197bff2-3100-7c5c-9d97-3d05faf3ab1a)\n",
      "Processing trace 120/288: run_016_gemma3:4b_0.0 (0197bfee-1021-7234-8843-279ca52d1c5c)\n",
      "Processing trace 121/288: run_016_gemma3:1b_0.0 (0197bfea-bd65-7190-8627-8b93134d9c77)\n",
      "Processing trace 122/288: run_015_smollm2:1.7b_0.0 (0197bfe9-7eea-7635-90f1-49c08e763b80)\n",
      "Processing trace 123/288: run_015_moondream:1.8b_0.0 (0197bfe9-660d-767b-9dbb-a7467f0c2269)\n",
      "Processing trace 124/288: run_015_llama3.2:1b_0.0 (0197bfe6-5899-7ba2-ac23-2b41c67dfee8)\n",
      "Processing trace 125/288: run_015_gemma3:4b_0.0 (0197bfd7-44ba-7b30-b1fa-2281a126efc3)\n",
      "Processing trace 126/288: run_016_deepseek-r1:1.5b_0.0 (0197bfd4-29da-788d-b6eb-d811ec9ade72)\n",
      "Processing trace 127/288: run_015_gemma3:1b_0.0 (0197bfd3-2b8f-7ba6-8e1a-3205bfbd08e3)\n",
      "Processing trace 128/288: run_014_qwen3:4b_0.2 (0197bfc2-cc8c-7b38-8a9b-70033cfa3ce0)\n",
      "Processing trace 129/288: run_015_deepseek-r1:1.5b_0.0 (0197bfb6-72ef-72a2-990d-94cc621d0d56)\n",
      "Processing trace 130/288: run_014_qwen3:1.7b_0.2 (0197bfb3-2430-7fd6-973a-2e1000f31cb6)\n",
      "Processing trace 131/288: run_013_qwen3:4b_0.2 (0197bf9a-85f2-7b8c-82df-71d224d39bc7)\n",
      "Processing trace 132/288: run_014_qwen3:0.6b_0.2 (0197bf94-f63c-7e53-9773-c91f1054b717)\n",
      "Processing trace 133/288: run_014_tinyllama:1.1b_0.2 (0197bf87-f9cd-782a-991c-2dde813a9f1f)\n",
      "Processing trace 134/288: run_014_smollm2:1.7b_0.2 (0197bf81-d265-7df1-a5c1-6eabc4bd4275)\n",
      "Processing trace 135/288: run_014_moondream:1.8b_0.2 (0197bf81-c01a-74af-8554-1466c10e9a7a)\n",
      "Processing trace 136/288: run_013_qwen3:1.7b_0.2 (0197bf7c-d081-769f-ba3e-2ebed32063e4)\n",
      "Processing trace 137/288: run_011_qwen3:4b_0.4 (0197bf7c-6d43-75f9-9122-e9392c1c7728)\n",
      "Processing trace 138/288: run_014_llama3.2:1b_0.2 (0197bf74-f1a2-7679-b620-e8da23fb366f)\n",
      "Processing trace 139/288: run_012_qwen3:4b_0.4 (0197bf71-94a8-7c2d-bc78-fa96751224e9)\n",
      "Processing trace 140/288: run_013_qwen3:0.6b_0.2 (0197bf6e-4ac1-7b6d-b46d-6425b1f81124)\n",
      "Processing trace 141/288: run_014_gemma3:4b_0.2 (0197bf62-9aa6-7b2f-9456-f185203eb01b)\n",
      "Processing trace 142/288: run_011_qwen3:1.7b_0.4 (0197bf61-9a21-78bc-b29c-b088fe5c86a4)\n",
      "Processing trace 143/288: run_013_tinyllama:1.1b_0.2 (0197bf58-f848-7f63-b4a0-19669f5f81cc)\n",
      "Processing trace 144/288: run_012_qwen3:1.7b_0.4 (0197bf55-592c-7716-ad6c-7dc7feecb2df)\n",
      "Processing trace 145/288: run_014_gemma3:1b_0.2 (0197bf53-8a78-7ec4-83ed-d915af15713e)\n",
      "Processing trace 146/288: run_013_smollm2:1.7b_0.2 (0197bf50-08a1-7724-a3f7-9546991afb25)\n",
      "Processing trace 147/288: run_013_moondream:1.8b_0.2 (0197bf4f-f441-7d99-93ad-272cd52ac3d6)\n",
      "Processing trace 148/288: run_011_qwen3:0.6b_0.4 (0197bf46-1bf5-7196-bab2-5aa2530a6aaf)\n",
      "Processing trace 149/288: run_013_llama3.2:1b_0.2 (0197bf45-3a37-7fb9-a9e1-4289adfa81d4)\n",
      "Processing trace 150/288: run_012_qwen3:0.6b_0.4 (0197bf42-8966-738c-a5b2-bbeadd461fac)\n",
      "Processing trace 151/288: run_013_gemma3:4b_0.2 (0197bf36-d727-7bb7-ab5a-b4f5c55a6c72)\n",
      "Processing trace 152/288: run_011_tinyllama:1.1b_0.4 (0197bf36-27d4-739d-a95a-b7208ed02cc6)\n",
      "Processing trace 153/288: run_012_tinyllama:1.1b_0.4 (0197bf35-1317-7e1d-9712-cf7e3bf701fb)\n",
      "Processing trace 154/288: run_014_deepseek-r1:1.5b_0.2 (0197bf34-fc57-704d-a4a8-7d6393f76737)\n",
      "Processing trace 155/288: run_012_smollm2:1.7b_0.4 (0197bf2b-129d-7708-9937-a7413e49e24a)\n",
      "Processing trace 156/288: run_013_gemma3:1b_0.2 (0197bf25-4b65-7bec-b9f8-49e42ad6ea85)\n",
      "Processing trace 157/288: run_011_smollm2:1.7b_0.4 (0197bf23-46ab-721d-8a0c-e05470870bcf)\n",
      "Processing trace 158/288: run_012_moondream:1.8b_0.4 (0197bf23-3305-787f-9963-e3efede66884)\n",
      "Processing trace 159/288: run_011_moondream:1.8b_0.4 (0197bf20-44f2-72e9-9c8d-957d63c08f6c)\n",
      "Processing trace 160/288: run_011_llama3.2:1b_0.4 (0197bf18-8e3e-74aa-ab4c-a78d46842823)\n",
      "Processing trace 161/288: run_010_qwen3:4b_0.0 (0197bf18-5468-7022-87bd-325d487b8ccb)\n",
      "Processing trace 162/288: run_012_llama3.2:1b_0.4 (0197bf0e-9c4c-70e1-9689-df79ae8a5803)\n",
      "Processing trace 163/288: run_011_gemma3:4b_0.4 (0197befe-75cc-7786-808c-83af03dc716d)\n",
      "Processing trace 164/288: run_010_qwen3:1.7b_0.0 (0197befd-28f6-77b1-b14a-941e3216be90)\n",
      "Processing trace 165/288: run_013_deepseek-r1:1.5b_0.2 (0197befd-1906-75d9-a373-a18d5dfcc889)\n",
      "Processing trace 166/288: run_012_gemma3:4b_0.4 (0197bef4-5d40-75bb-8b70-ca6750afcb1c)\n",
      "Processing trace 167/288: run_001_qwen3:4b_0.4 (0197beef-2217-7e4a-9cf6-9a6a4b6c2710)\n",
      "Processing trace 168/288: run_011_gemma3:1b_0.4 (0197bee9-8299-7b84-95ad-6d0923ffd0b8)\n",
      "Processing trace 169/288: run_012_gemma3:1b_0.4 (0197bedc-b687-7680-bc60-c64c5d7266f1)\n",
      "Processing trace 170/288: run_001_qwen3:1.7b_0.4 (0197bedb-dc96-7e09-bc9b-041ba4ac0870)\n",
      "Processing trace 171/288: run_010_qwen3:0.6b_0.0 (0197bed9-3a86-780e-b911-46153e77cd47)\n",
      "Processing trace 172/288: run_009_qwen3:4b_0.0 (0197bed7-c8fc-7af6-93cf-0f72038b6976)\n",
      "Processing trace 173/288: run_010_tinyllama:1.1b_0.0 (0197bece-4f37-7ad8-b01d-5b2fc4d02b7a)\n",
      "Processing trace 174/288: run_010_smollm2:1.7b_0.0 (0197bec9-4cf8-7a1c-8acf-94f4c22fdb97)\n",
      "Processing trace 175/288: run_010_moondream:1.8b_0.0 (0197bec9-3daf-72e8-9626-45c2573c9d8c)\n",
      "Processing trace 176/288: run_010_llama3.2:1b_0.0 (0197bec2-c3e0-7f61-b7ca-51873e382830)\n",
      "Processing trace 177/288: run_009_qwen3:1.7b_0.0 (0197bebe-b8e7-733d-83f4-32502e0a3d5d)\n",
      "Processing trace 178/288: run_012_deepseek-r1:1.5b_0.4 (0197bebb-311a-7959-9c4b-c1caefea286e)\n",
      "Processing trace 179/288: run_011_deepseek-r1:1.5b_0.4 (0197beb4-7d2f-795b-bb0d-2a19432a1097)\n",
      "Processing trace 180/288: run_009_qwen3:0.6b_0.0 (0197beaa-ff6d-79b5-bedf-db2f3e3f8520)\n",
      "Processing trace 181/288: run_001_qwen3:4b_0.4 (0197bea9-0b46-703d-9603-3a83ecf2e320)\n",
      "Processing trace 182/288: run_010_gemma3:4b_0.0 (0197bea8-3e8b-77b9-ae65-e661142c1065)\n",
      "Processing trace 183/288: run_010_gemma3:1b_0.0 (0197be9e-3275-70f7-bd62-21338a61a4cf)\n",
      "Processing trace 184/288: run_009_tinyllama:1.1b_0.0 (0197be95-6bc8-704d-81d6-2ac134e451e3)\n",
      "Processing trace 185/288: run_008_qwen3:4b_0.4 (0197be91-e662-7e71-bcb2-8e65aed3a9d5)\n",
      "Processing trace 186/288: run_001_qwen3:0.6b_0.4 (0197be8f-b477-729e-8684-0370a268debe)\n",
      "Processing trace 187/288: run_007_qwen3:4b_0.4 (0197be8c-7a23-77b7-bab1-920b74c4655c)\n",
      "Processing trace 188/288: run_009_smollm2:1.7b_0.0 (0197be8a-9535-7d96-9b7d-e533cba9ddc3)\n",
      "Processing trace 189/288: run_009_moondream:1.8b_0.0 (0197be8a-7da0-7d25-a3bd-d6a36738fdaf)\n",
      "Processing trace 190/288: run_007_qwen3:1.7b_0.4 (0197be88-bc37-782a-b597-79d728ce9bfc)\n",
      "Processing trace 191/288: run_009_llama3.2:1b_0.0 (0197be76-fa07-7861-8a5e-a23fa4bb609a)\n",
      "Processing trace 192/288: run_008_qwen3:1.7b_0.4 (0197be76-7939-7f2b-9d68-bebc61c31a6b)\n",
      "Processing trace 193/288: run_010_deepseek-r1:1.5b_0.0 (0197be73-caaf-767f-bee3-e4c20fd16096)\n",
      "Processing trace 194/288: run_007_qwen3:0.6b_0.4 (0197be67-4568-7a9b-9f83-2a873635741b)\n",
      "Processing trace 195/288: run_009_gemma3:4b_0.0 (0197be65-034e-77ab-b45d-4e5e5ccd06f1)\n",
      "Processing trace 196/288: run_008_qwen3:0.6b_0.4 (0197be5f-01d7-7107-ba8c-69ffe845dc5a)\n",
      "Processing trace 197/288: run_001_qwen3:1.7b_0.4 (0197be5c-ba88-7273-9c7d-591c7a9b76ca)\n",
      "Processing trace 198/288: run_001_tinyllama:1.1b_0.4 (0197be5a-61c5-7a47-a50e-7d81b24a5583)\n",
      "Processing trace 199/288: run_009_gemma3:1b_0.0 (0197be56-26ba-7329-a759-252e102f0475)\n",
      "Processing trace 200/288: run_006_qwen3:4b_0.2 (0197be54-6b1b-7d00-bee1-38541c8d861f)\n",
      "Processing trace 201/288: run_007_tinyllama:1.1b_0.4 (0197be54-04a1-7285-a0e5-977e7308ed34)\n",
      "Processing trace 202/288: run_008_tinyllama:1.1b_0.4 (0197be51-1a59-7c23-a17d-065f9579fbcf)\n",
      "Processing trace 203/288: run_006_qwen3:1.7b_0.2 (0197be4d-64de-729e-991c-7aad9f355aca)\n",
      "Processing trace 204/288: run_008_smollm2:1.7b_0.4 (0197be46-5c70-72c5-8a4c-f1712d887932)\n",
      "Processing trace 205/288: run_007_smollm2:1.7b_0.4 (0197be45-a99a-7f5f-8443-f7d2270d75c4)\n",
      "Processing trace 206/288: run_007_moondream:1.8b_0.4 (0197be45-9299-79a9-8a07-407ce816ba3c)\n",
      "Processing trace 207/288: run_008_moondream:1.8b_0.4 (0197be41-b852-70f1-930a-9f49e4eea235)\n",
      "Processing trace 208/288: run_007_llama3.2:1b_0.4 (0197be3e-2f8f-74a4-b1e0-0cb2ac9290b7)\n",
      "Processing trace 209/288: run_009_deepseek-r1:1.5b_0.0 (0197be3b-7bf8-7487-9e0a-97e3f911d6c4)\n",
      "Processing trace 210/288: run_001_qwen3:0.6b_0.4 (0197be32-1dc5-70d8-bf7f-2d6b68c3cb0e)\n",
      "Processing trace 211/288: run_008_llama3.2:1b_0.4 (0197be2e-561a-7878-b28f-8c52f189a521)\n",
      "Processing trace 212/288: run_001_smollm2:1.7b_0.4 (0197be2b-f91e-7012-8755-11bc56f97e48)\n",
      "Processing trace 213/288: run_001_moondream:1.8b_0.4 (0197be2b-20f3-76c3-ba3c-9d79d3f8a3e1)\n",
      "Processing trace 214/288: run_006_qwen3:0.6b_0.2 (0197be2a-f7d2-7233-9181-ace29ce91c22)\n",
      "Processing trace 215/288: run_001_tinyllama:1.1b_0.4 (0197be1c-0653-7406-8e05-cf2dd8421a11)\n",
      "Processing trace 216/288: run_006_tinyllama:1.1b_0.2 (0197be1a-5653-7b83-8a91-82da59bb08b6)\n",
      "Processing trace 217/288: run_007_gemma3:4b_0.4 (0197be18-acac-7637-abd4-eca32c7fdee7)\n",
      "Processing trace 218/288: run_005_qwen3:4b_0.2 (0197be11-cbe2-72e1-b007-f77c2f928477)\n",
      "Processing trace 219/288: run_001_llama3.2:1b_0.4 (0197be0f-9c30-7fe9-bd3a-7ac8f2d83a50)\n",
      "Processing trace 220/288: run_008_gemma3:4b_0.4 (0197be0f-6ef9-7c5a-bfa6-d6937b0dd77c)\n",
      "Processing trace 221/288: run_006_smollm2:1.7b_0.2 (0197be0c-8414-795c-863e-3b7400bfdd14)\n",
      "Processing trace 222/288: run_006_moondream:1.8b_0.2 (0197be0c-760e-7c43-823a-408b8a78f2b2)\n",
      "Processing trace 223/288: run_006_llama3.2:1b_0.2 (0197be07-3fb3-7228-b50f-90cf7050b13a)\n",
      "Processing trace 224/288: run_001_smollm2:1.7b_0.4 (0197be03-ebec-7485-a228-15b79cfffae6)\n",
      "Processing trace 225/288: run_007_gemma3:1b_0.4 (0197be03-c1d2-7034-ac7b-07ac1d23ddd8)\n",
      "Processing trace 226/288: run_001_moondream:1.8b_0.4 (0197be03-1298-75f9-9e19-9982a782cac6)\n",
      "Processing trace 227/288: run_008_gemma3:1b_0.4 (0197be00-9ff3-7e90-a0c2-0a9bbd396d52)\n",
      "Processing trace 228/288: run_005_qwen3:1.7b_0.2 (0197bdf8-75df-7a79-991d-6af90fcacbb2)\n",
      "Processing trace 229/288: run_001_llama3.2:1b_0.4 (0197bdeb-9802-7db5-8cc1-f297f9539bab)\n",
      "Processing trace 230/288: run_005_qwen3:0.6b_0.2 (0197bdea-2c72-7173-bca0-179d7955828e)\n",
      "Processing trace 231/288: run_006_gemma3:4b_0.2 (0197bde4-9745-7007-862f-34d2bbba9fb1)\n",
      "Processing trace 232/288: run_005_tinyllama:1.1b_0.2 (0197bde4-17c7-7ec1-8af7-766934c95998)\n",
      "Processing trace 233/288: run_006_gemma3:1b_0.2 (0197bdde-3462-74ce-bb17-e555522d8d2c)\n",
      "Processing trace 234/288: run_005_smollm2:1.7b_0.2 (0197bddd-7b67-7dd9-9529-b25519a23ddb)\n",
      "Processing trace 235/288: run_005_moondream:1.8b_0.2 (0197bddd-6988-7016-b47a-0e69b5dcc8b0)\n",
      "Processing trace 236/288: run_008_deepseek-r1:1.5b_0.4 (0197bdda-2014-775d-a63c-237d2515e083)\n",
      "Processing trace 237/288: run_005_llama3.2:1b_0.2 (0197bdd7-d95c-7414-8650-8c19124ab050)\n",
      "Processing trace 238/288: run_007_deepseek-r1:1.5b_0.4 (0197bdd3-da1e-7ea8-abed-ac045ac0cbdc)\n",
      "Processing trace 239/288: run_005_gemma3:4b_0.2 (0197bdb8-38be-7736-bfb5-9513184a50b6)\n",
      "Processing trace 240/288: run_006_deepseek-r1:1.5b_0.2 (0197bdb7-9cdb-77c1-87cf-18699ada7cc0)\n",
      "Processing trace 241/288: run_005_gemma3:1b_0.2 (0197bdae-82a7-7229-af4d-00818791efdc)\n",
      "Processing trace 242/288: run_004_qwen3:4b_0.4 (0197bdaa-463f-78f0-a83c-a2ce8d3260a4)\n",
      "Processing trace 243/288: run_003_qwen3:4b_0.4 (0197bda8-c217-70a1-9d32-db8744d8b97a)\n",
      "Processing trace 244/288: run_001_gemma3:4b_0.4 (0197bda4-d075-7f85-b0ba-8cfc92fdf22f)\n",
      "Processing trace 245/288: run_001_gemma3:4b_0.4 (0197bd97-96d6-7be2-9299-aff96a9a7e0f)\n",
      "Processing trace 246/288: run_001_qwen3:4b_0.0 (0197bd97-2a8d-7dc0-8dae-81bc931933bf)\n",
      "Processing trace 247/288: run_004_qwen3:1.7b_0.4 (0197bd95-eaca-7b7b-bf6b-a00bc6841494)\n",
      "Processing trace 248/288: run_001_qwen3:1.7b_0.0 (0197bd90-bc6a-73af-8309-fcb101a0c082)\n",
      "Processing trace 249/288: run_005_deepseek-r1:1.5b_0.2 (0197bd8c-f0f3-7a35-acc2-7741f0089cbc)\n",
      "Processing trace 250/288: run_003_qwen3:1.7b_0.4 (0197bd88-a498-76b8-a26e-5bcced5d0a45)\n",
      "Processing trace 251/288: run_001_gemma3:1b_0.4 (0197bd7a-ab21-7583-b1b5-6d9b1da17299)\n",
      "Processing trace 252/288: run_002_qwen3:4b_0.0 (0197bd70-2287-7518-b754-3d9622811114)\n",
      "Processing trace 253/288: run_004_qwen3:0.6b_0.4 (0197bd6f-de2c-746f-9213-f4a7c85f03fa)\n",
      "Processing trace 254/288: run_003_qwen3:0.6b_0.4 (0197bd6e-533a-78e9-8f8d-bc419041f277)\n",
      "Processing trace 255/288: run_001_qwen3:0.6b_0.0 (0197bd6a-23a9-7934-bac2-d81eebfea5ee)\n",
      "Processing trace 256/288: run_001_gemma3:1b_0.4 (0197bd62-05f2-7068-b488-9e07003a16f4)\n",
      "Processing trace 257/288: run_003_tinyllama:1.1b_0.4 (0197bd61-b321-7fd7-b090-9fe8a17e4a81)\n",
      "Processing trace 258/288: run_004_tinyllama:1.1b_0.4 (0197bd61-62f4-78da-a41d-7cc1d84f48d1)\n",
      "Processing trace 259/288: run_002_qwen3:1.7b_0.0 (0197bd5a-adb5-7976-bf4b-48418415993d)\n",
      "Processing trace 260/288: run_001_tinyllama:1.1b_0.0 (0197bd59-2307-7689-a47e-350f482c3d1c)\n",
      "Processing trace 261/288: run_004_smollm2:1.7b_0.4 (0197bd58-1de4-7187-bc44-392e24c3ae1b)\n",
      "Processing trace 262/288: run_003_smollm2:1.7b_0.4 (0197bd58-1993-7ea1-af15-3d672ab18db3)\n",
      "Processing trace 263/288: run_004_moondream:1.8b_0.4 (0197bd57-f9e2-765f-8c6e-80f848ab17d6)\n",
      "Processing trace 264/288: run_003_moondream:1.8b_0.4 (0197bd51-2595-7ee9-a7ca-d5b6c80e4656)\n",
      "Processing trace 265/288: run_001_smollm2:1.7b_0.0 (0197bd4e-a6a7-712f-a500-c93cf496ce85)\n",
      "Processing trace 266/288: run_001_moondream:1.8b_0.0 (0197bd4e-8563-7bbb-8029-837ae5600490)\n",
      "Processing trace 267/288: run_004_llama3.2:1b_0.4 (0197bd4d-bb0b-7350-a496-9c00051fcd2b)\n",
      "Processing trace 268/288: run_002_qwen3:0.6b_0.0 (0197bd4c-7bac-7a1a-ad1a-45e3754da907)\n",
      "Processing trace 269/288: run_003_llama3.2:1b_0.4 (0197bd47-ca95-723b-92d0-8eb2dac3d437)\n",
      "Processing trace 270/288: run_002_tinyllama:1.1b_0.0 (0197bd46-73a5-7d77-8b3a-c570885edfef)\n",
      "Processing trace 271/288: run_001_llama3.2:1b_0.0 (0197bd45-e1db-7b19-8abe-8f6a3f1d6042)\n",
      "Processing trace 272/288: run_002_smollm2:1.7b_0.0 (0197bd3f-d807-7d70-b714-a2749d564571)\n",
      "Processing trace 273/288: run_002_moondream:1.8b_0.0 (0197bd3f-c541-7651-b0e9-6910a7b8e140)\n",
      "Processing trace 274/288: run_002_llama3.2:1b_0.0 (0197bd39-7825-771f-b523-658bbda080f4)\n",
      "Processing trace 275/288: run_004_gemma3:4b_0.4 (0197bd39-0c64-7b26-b934-b6aeca064560)\n",
      "Processing trace 276/288: run_003_gemma3:4b_0.4 (0197bd31-7db4-7205-a012-91c8da9a04fb)\n",
      "Processing trace 277/288: run_004_gemma3:1b_0.4 (0197bd30-b40e-79cd-adc0-c3f1ba814c7f)\n",
      "Processing trace 278/288: run_001_gemma3:4b_0.0 (0197bd2b-effb-7c5f-baa1-978412209aac)\n",
      "Processing trace 279/288: run_003_gemma3:1b_0.4 (0197bd28-37e7-7077-94cc-378a4442fe23)\n",
      "Processing trace 280/288: run_002_gemma3:4b_0.0 (0197bd27-84d2-7ec9-adfd-1de4a917e159)\n",
      "Processing trace 281/288: run_001_gemma3:1b_0.0 (0197bd24-bf96-76b2-a67c-aff3882ddfbc)\n",
      "Processing trace 282/288: run_002_gemma3:1b_0.0 (0197bd22-0c97-79b3-8ebe-ae385d1ce98d)\n",
      "Processing trace 283/288: run_004_deepseek-r1:1.5b_0.4 (0197bd06-b2c3-7f4b-9ad8-81f6dd9b27b2)\n",
      "Processing trace 284/288: run_003_deepseek-r1:1.5b_0.4 (0197bd06-69b0-7bf8-a7e4-b810caef1a73)\n",
      "Processing trace 285/288: run_001_deepseek-r1:1.5b_0.4 (0197bd05-09aa-77bf-9ede-b0c5b0b6d762)\n",
      "Processing trace 286/288: run_001_deepseek-r1:1.5b_0.4 (0197bd04-f7c5-7971-a387-d34a5bab4a4c)\n",
      "Processing trace 287/288: run_002_deepseek-r1:1.5b_0.0 (0197bd04-7801-767b-9617-208ae407f61b)\n",
      "Processing trace 288/288: run_001_deepseek-r1:1.5b_0.0 (0197bd04-3e8f-7ca6-a9a2-71201bb23e96)\n"
     ]
    }
   ],
   "source": [
    "# Get all the data of Opik determinism project\n",
    "all_opik_data = get_opik_flat_data_for_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e01cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full DataFrame loaded with shape: (28800, 20)\n",
      "INFO: Total of 2726 failed responses (timeout, empty answer or infinite loop).\n",
      "DataFrame after preprocessing:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "DataFrame head:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "DataFrame shape: (28800, 22)\n",
      "\n",
      "Successfully extracted data and saved to ../../../data/determinism/opik_determinism_data.csv\n",
      "DataFrame after preprocessing:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Filtered DataFrame for temperature = 0.0:\n",
      "DataFrame head:\n",
      "                                  span_id span_name  response_time  \\\n",
      "700  0197c87c-003c-70f7-8124-2bb689124e3a   q10_r10         93.583   \n",
      "701  0197c87a-92ad-73a2-8e73-161000c7872e    q10_r9         33.799   \n",
      "702  0197c87a-0ea6-7391-a966-0f4fc303768f    q10_r8         93.561   \n",
      "703  0197c878-a12d-7635-baae-a7777c19a393    q10_r7         35.557   \n",
      "704  0197c878-1648-7e94-9106-270348204e3f    q10_r6         23.474   \n",
      "\n",
      "                                   span_input_question  \\\n",
      "700  What is the sum of the binary numbers 11100101...   \n",
      "701  What is the sum of the binary numbers 11100101...   \n",
      "702  What is the sum of the binary numbers 11100101...   \n",
      "703  What is the sum of the binary numbers 11100101...   \n",
      "704  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "                 span_output_answer  \\\n",
      "700                                   \n",
      "701     [a][b][c][d][e][f][b][b][b]   \n",
      "702                             [a]   \n",
      "703        [a][b][c][d][e][f][c][c]   \n",
      "704  [a][b][c][d][e][f][b][b][b][b]   \n",
      "\n",
      "                                span_output_raw_answer span_correct_answer  \\\n",
      "700  [[ ## thought ## ]] The question asks for the ...                   c   \n",
      "701  [[ ## thought ## ]] The question asks for the ...                   c   \n",
      "702  [[ ## thought ## ]] The question asks for the ...                   c   \n",
      "703  [[ ## thought ## ]] The question asks for the ...                   c   \n",
      "704  [[ ## thought ## ]] The question asks for the ...                   c   \n",
      "\n",
      "     completion_tokens    question_file                              trace_id  \\\n",
      "700                  0  question_10.txt  0197c861-b223-75f6-9e6b-e9cdd55da5a7   \n",
      "701                  0  question_10.txt  0197c861-b223-75f6-9e6b-e9cdd55da5a7   \n",
      "702                  0  question_10.txt  0197c861-b223-75f6-9e6b-e9cdd55da5a7   \n",
      "703                  0  question_10.txt  0197c861-b223-75f6-9e6b-e9cdd55da5a7   \n",
      "704                  0  question_10.txt  0197c861-b223-75f6-9e6b-e9cdd55da5a7   \n",
      "\n",
      "     ... language prompting_tech num_runs_per_question model_source  \\\n",
      "700  ...       en             R2                    10        local   \n",
      "701  ...       en             R2                    10        local   \n",
      "702  ...       en             R2                    10        local   \n",
      "703  ...       en             R2                    10        local   \n",
      "704  ...       en             R2                    10        local   \n",
      "\n",
      "     temperature top_p    exercise    question_type is_failure  \\\n",
      "700          0.0   0.1  exam_01_mc  multiple_choice      False   \n",
      "701          0.0   0.1  exam_01_mc  multiple_choice      False   \n",
      "702          0.0   0.1  exam_01_mc  multiple_choice      False   \n",
      "703          0.0   0.1  exam_01_mc  multiple_choice      False   \n",
      "704          0.0   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                                answer  \n",
      "700  [[ ## thought ## ]] The question asks for the ...  \n",
      "701  [[ ## thought ## ]] The question asks for the ...  \n",
      "702  [[ ## thought ## ]] The question asks for the ...  \n",
      "703  [[ ## thought ## ]] The question asks for the ...  \n",
      "704  [[ ## thought ## ]] The question asks for the ...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "DataFrame shape: (9600, 22)\n",
      "\n",
      "Successfully extracted data and saved to ../../../data/determinism/opik_determinism_data_temp_00.csv\n",
      "DataFrame after preprocessing:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Filtered DataFrame for temperature = 0.2:\n",
      "DataFrame head:\n",
      "                                  span_id span_name  response_time  \\\n",
      "300  0197c8a8-babe-7651-ad7a-d41af3bcb724   q10_r10          5.557   \n",
      "301  0197c8a8-a50a-7ee9-bc26-0292d0f510d5    q10_r9          5.698   \n",
      "302  0197c8a8-8ec7-785b-92fe-917c2d35c87f    q10_r8          5.699   \n",
      "303  0197c8a8-7884-7232-879c-36f83e662e4e    q10_r7          5.671   \n",
      "304  0197c8a8-625d-7faf-8b30-fe37283e45f1    q10_r6          5.798   \n",
      "\n",
      "                                   span_input_question span_output_answer  \\\n",
      "300  What is the sum of the binary numbers 11100101...                [c]   \n",
      "301  What is the sum of the binary numbers 11100101...                [c]   \n",
      "302  What is the sum of the binary numbers 11100101...                [a]   \n",
      "303  What is the sum of the binary numbers 11100101...                [a]   \n",
      "304  What is the sum of the binary numbers 11100101...                [c]   \n",
      "\n",
      "                                span_output_raw_answer span_correct_answer  \\\n",
      "300  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "301  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "302  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "303  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "304  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "     completion_tokens    question_file                              trace_id  \\\n",
      "300                  0  question_10.txt  0197c883-02b8-75d4-94ab-027f86e69f2d   \n",
      "301                  0  question_10.txt  0197c883-02b8-75d4-94ab-027f86e69f2d   \n",
      "302                  0  question_10.txt  0197c883-02b8-75d4-94ab-027f86e69f2d   \n",
      "303                  0  question_10.txt  0197c883-02b8-75d4-94ab-027f86e69f2d   \n",
      "304                  0  question_10.txt  0197c883-02b8-75d4-94ab-027f86e69f2d   \n",
      "\n",
      "     ... language prompting_tech num_runs_per_question model_source  \\\n",
      "300  ...       en             R2                    10        local   \n",
      "301  ...       en             R2                    10        local   \n",
      "302  ...       en             R2                    10        local   \n",
      "303  ...       en             R2                    10        local   \n",
      "304  ...       en             R2                    10        local   \n",
      "\n",
      "     temperature top_p    exercise    question_type is_failure  \\\n",
      "300          0.2   0.1  exam_01_mc  multiple_choice      False   \n",
      "301          0.2   0.1  exam_01_mc  multiple_choice      False   \n",
      "302          0.2   0.1  exam_01_mc  multiple_choice      False   \n",
      "303          0.2   0.1  exam_01_mc  multiple_choice      False   \n",
      "304          0.2   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                                answer  \n",
      "300  [[ ## question ## ]] What is the sum of the bi...  \n",
      "301  [[ ## question ## ]] What is the sum of the bi...  \n",
      "302  [[ ## question ## ]] What is the sum of the bi...  \n",
      "303  [[ ## question ## ]] What is the sum of the bi...  \n",
      "304  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "DataFrame shape: (9600, 22)\n",
      "\n",
      "Successfully extracted data and saved to ../../../data/determinism/opik_determinism_data_temp_02.csv\n",
      "DataFrame after preprocessing:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Filtered DataFrame for temperature = 0.4:\n",
      "DataFrame head:\n",
      "                                span_id span_name  response_time  \\\n",
      "0  0197ca25-6aed-7665-a917-c196a22e8f78   q10_r10          2.681   \n",
      "1  0197ca25-6074-7cd4-ac99-1ff5bc88c160    q10_r9          2.733   \n",
      "2  0197ca25-55c7-720e-ae89-2ce0b23ed34e    q10_r8          2.778   \n",
      "3  0197ca25-4aed-798e-b642-85dd7af33ef9    q10_r7          2.812   \n",
      "4  0197ca25-3ff0-7562-9261-395b44060d78    q10_r6          8.288   \n",
      "\n",
      "                                 span_input_question  \\\n",
      "0  What is the sum of the binary numbers 11100101...   \n",
      "1  What is the sum of the binary numbers 11100101...   \n",
      "2  What is the sum of the binary numbers 11100101...   \n",
      "3  What is the sum of the binary numbers 11100101...   \n",
      "4  What is the sum of the binary numbers 11100101...   \n",
      "\n",
      "         span_output_answer  \\\n",
      "0                       [a]   \n",
      "1                       [a]   \n",
      "2                       [a]   \n",
      "3                       [a]   \n",
      "4  [a][b][c][d][e][f][a][a]   \n",
      "\n",
      "                              span_output_raw_answer span_correct_answer  \\\n",
      "0  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "1  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "2  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "3  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "4  [[ ## question ## ]] What is the sum of the bi...                   c   \n",
      "\n",
      "   completion_tokens    question_file                              trace_id  \\\n",
      "0                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "1                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "2                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "3                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "4                  0  question_10.txt  0197ca15-127b-7a01-8d4c-721291544b29   \n",
      "\n",
      "   ... language prompting_tech num_runs_per_question model_source  \\\n",
      "0  ...       en             R4                    10        local   \n",
      "1  ...       en             R4                    10        local   \n",
      "2  ...       en             R4                    10        local   \n",
      "3  ...       en             R4                    10        local   \n",
      "4  ...       en             R4                    10        local   \n",
      "\n",
      "   temperature top_p    exercise    question_type is_failure  \\\n",
      "0          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "1          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "2          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "3          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "4          0.4   0.1  exam_01_mc  multiple_choice      False   \n",
      "\n",
      "                                              answer  \n",
      "0  [[ ## question ## ]] What is the sum of the bi...  \n",
      "1  [[ ## question ## ]] What is the sum of the bi...  \n",
      "2  [[ ## question ## ]] What is the sum of the bi...  \n",
      "3  [[ ## question ## ]] What is the sum of the bi...  \n",
      "4  [[ ## question ## ]] What is the sum of the bi...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "DataFrame shape: (9600, 22)\n",
      "\n",
      "Successfully extracted data and saved to ../../../data/determinism/opik_determinism_data_temp_04.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all the info from Opik (traces and spans) and create a DataFrame and CSV file for each temperature\n",
    "if all_opik_data:\n",
    "    full_df = pd.DataFrame(all_opik_data).copy()\n",
    "    print(f\"\\nFull DataFrame loaded with shape: {full_df.shape}\")\n",
    "    \n",
    "    full_df = preprocess_and_identify_failures(full_df)\n",
    "    \n",
    "    # Save full dataframe\n",
    "    filter_and_save_dataframe(full_df)\n",
    "\n",
    "    # Dataframe with temperature=0.0\n",
    "    filter_and_save_dataframe(full_df, csv_filename=\"opik_determinism_data_temp_00.csv\", temperature_filter=0.0)\n",
    "\n",
    "    # Dataframe with temperature=0.2\n",
    "    filter_and_save_dataframe(full_df, csv_filename=\"opik_determinism_data_temp_02.csv\", temperature_filter=0.2)\n",
    "    \n",
    "    # Dataframe with temperature=0.4\n",
    "    filter_and_save_dataframe(full_df, csv_filename=\"opik_determinism_data_temp_04.csv\", temperature_filter=0.4)\n",
    "\n",
    "else:\n",
    "    print(\"No data fetched from Opik to create any CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from ../../../data/determinism/opik_determinism_data_temp_00.csv with shape: (9600, 22)\n",
      "MODELS:  ['Gemma3:1b' 'Qwen3:1.7b' 'TinyLlama:1.1b' 'DeepSeek R1:1.5b'\n",
      " 'Llama3.2:1b' 'Gemma3n:e4b' 'smollm2:1.7b' 'Qwen3:4b' 'Gemma3n:e2b'\n",
      " 'Qwen3:0.6b' 'Gemma3:4b' 'Moondream 2']\n",
      "\n",
      "Columns in                           run_name model_display_name    question_file  \\\n",
      "0            run_001_gemma3:1b_0.0          Gemma3:1b  question_01.txt   \n",
      "1            run_001_gemma3:1b_0.0          Gemma3:1b  question_01.txt   \n",
      "2            run_001_gemma3:1b_0.0          Gemma3:1b  question_01.txt   \n",
      "3            run_001_gemma3:1b_0.0          Gemma3:1b  question_01.txt   \n",
      "4            run_001_gemma3:1b_0.0          Gemma3:1b  question_01.txt   \n",
      "...                            ...                ...              ...   \n",
      "4795  run_001_deepseek-r1:1.5b_0.0   DeepSeek R1:1.5b  question_10.txt   \n",
      "4796  run_001_deepseek-r1:1.5b_0.0   DeepSeek R1:1.5b  question_10.txt   \n",
      "4797  run_001_deepseek-r1:1.5b_0.0   DeepSeek R1:1.5b  question_10.txt   \n",
      "4798  run_001_deepseek-r1:1.5b_0.0   DeepSeek R1:1.5b  question_10.txt   \n",
      "4799  run_001_deepseek-r1:1.5b_0.0   DeepSeek R1:1.5b  question_10.txt   \n",
      "\n",
      "                                                 answer correct_answer  \\\n",
      "0     Here's a step-by-step breakdown of how to conv...              b   \n",
      "1     Here's a step-by-step explanation to determine...              b   \n",
      "2     Here's a step-by-step explanation to determine...              b   \n",
      "3     Here's a step-by-step explanation to determine...              b   \n",
      "4     Here's a step-by-step explanation to determine...              b   \n",
      "...                                                 ...            ...   \n",
      "4795                                _OVERTHINK_FAILURE_              c   \n",
      "4796                                _OVERTHINK_FAILURE_              c   \n",
      "4797                                _OVERTHINK_FAILURE_              c   \n",
      "4798                                _OVERTHINK_FAILURE_              c   \n",
      "4799                                _OVERTHINK_FAILURE_              c   \n",
      "\n",
      "     prompting_tech  is_failure  \\\n",
      "0                R1        True   \n",
      "1                R1        True   \n",
      "2                R1        True   \n",
      "3                R1        True   \n",
      "4                R1        True   \n",
      "...             ...         ...   \n",
      "4795             R1        True   \n",
      "4796             R1        True   \n",
      "4797             R1        True   \n",
      "4798             R1        True   \n",
      "4799             R1        True   \n",
      "\n",
      "                                              reasoning      final_answer  \n",
      "0                                      _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "1                                      _FORMAT_FAILURE_                 c  \n",
      "2                                      _FORMAT_FAILURE_                 c  \n",
      "3                                      _FORMAT_FAILURE_                 a  \n",
      "4     The question asks for the binary representatio...  _FORMAT_FAILURE_  \n",
      "...                                                 ...               ...  \n",
      "4795                                   _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "4796                                   _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "4797                                   _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "4798                                   _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "4799                                   _FORMAT_FAILURE_  _FORMAT_FAILURE_  \n",
      "\n",
      "[4800 rows x 9 columns]:\n",
      "['run_name', 'model_display_name', 'question_file', 'answer', 'correct_answer', 'prompting_tech', 'is_failure', 'reasoning', 'final_answer']\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_01.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.69\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_02.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_02.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.51\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_03.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_03.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_04.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_05.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_06.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_06.txt', 'R3')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_06.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.47\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_07.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.68\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_08.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.79\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_09.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('DeepSeek R1:1.5b', 'question_10.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_01.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_02.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_02.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_03.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_03.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_03.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_03.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_04.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_05.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_05.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_05.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_06.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_06.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_06.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_07.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_07.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_07.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_08.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_09.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_09.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:1b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:1b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:1b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:1b', 'question_10.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_01.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_02.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_02.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_03.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_03.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_03.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_03.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_04.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_05.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_05.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_05.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_06.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_06.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_06.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_07.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_07.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_07.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_08.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_09.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_09.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('Gemma3:4b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('Gemma3:4b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('Gemma3:4b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('Gemma3:4b', 'question_10.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.61\n",
      "---- CONSISTENCY ANSWER:  0.6\n",
      "---- CONSISTENCY REASONING:  0.85\n",
      "---- CONSISTENCY ANSWER:  0.8\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.8\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.6\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.7\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.79\n",
      "---- CONSISTENCY ANSWER:  0.11\n",
      "---- CONSISTENCY REASONING:  0.72\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.91\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.46\n",
      "---- CONSISTENCY ANSWER:  0.14\n",
      "---- CONSISTENCY REASONING:  0.54\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.45\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.62\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.45\n",
      "---- CONSISTENCY ANSWER:  0.11\n",
      "---- CONSISTENCY REASONING:  0.75\n",
      "---- CONSISTENCY ANSWER:  0.25\n",
      "---- CONSISTENCY REASONING:  0.53\n",
      "---- CONSISTENCY ANSWER:  0.33\n",
      "---- CONSISTENCY REASONING:  0.56\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.48\n",
      "---- CONSISTENCY ANSWER:  0.25\n",
      "---- CONSISTENCY REASONING:  0.53\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.68\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.5\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.88\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.91\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.88\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.6\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.96\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.62\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.88\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.9\n",
      "---- CONSISTENCY ANSWER:  0.11\n",
      "---- CONSISTENCY REASONING:  0.73\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.89\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.95\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.7\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.7\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.7\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.96\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.86\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.9\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.5\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.5\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.93\n",
      "---- CONSISTENCY ANSWER:  0.14\n",
      "---- CONSISTENCY REASONING:  0.55\n",
      "---- CONSISTENCY ANSWER:  0.14\n",
      "---- CONSISTENCY REASONING:  0.49\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.89\n",
      "---- CONSISTENCY ANSWER:  0.14\n",
      "---- CONSISTENCY REASONING:  0.53\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.61\n",
      "---- CONSISTENCY ANSWER:  0.14\n",
      "---- CONSISTENCY REASONING:  0.53\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.22\n",
      "---- CONSISTENCY REASONING:  0.77\n",
      "---- CONSISTENCY ANSWER:  0.7\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.8\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.9\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.87\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.61\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.63\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.96\n",
      "---- CONSISTENCY ANSWER:  0.1\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "No successful runs for group ('Llama3.2:1b', 'question_01.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_02.txt', 'R1')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "No successful runs for group ('Llama3.2:1b', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_02.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "No successful runs for group ('Llama3.2:1b', 'question_03.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_04.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_05.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_05.txt', 'R2')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_05.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_06.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.81\n",
      "No successful runs for group ('Llama3.2:1b', 'question_07.txt', 'R1')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.95\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "No successful runs for group ('Llama3.2:1b', 'question_07.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_08.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_09.txt', 'R1')\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "No successful runs for group ('Llama3.2:1b', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('Llama3.2:1b', 'question_10.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_01.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_02.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_02.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_03.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_03.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_03.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_03.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_04.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_05.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_05.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_05.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_06.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_06.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_06.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_07.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_07.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_07.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_08.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_09.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_09.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('Moondream 2', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('Moondream 2', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('Moondream 2', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('Moondream 2', 'question_10.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.78\n",
      "---- CONSISTENCY REASONING:  0.79\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.81\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.95\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.81\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_03.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_03.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.33\n",
      "---- CONSISTENCY REASONING:  0.57\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_04.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.65\n",
      "---- CONSISTENCY ANSWER:  0.83\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_06.txt', 'R1')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_06.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.96\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.59\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_07.txt', 'R3')\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_07.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.25\n",
      "---- CONSISTENCY REASONING:  0.63\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.56\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_08.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.81\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.44\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_09.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.48\n",
      "---- CONSISTENCY ANSWER:  0.8\n",
      "---- CONSISTENCY REASONING:  0.45\n",
      "---- CONSISTENCY ANSWER:  0.17\n",
      "---- CONSISTENCY REASONING:  0.44\n",
      "---- CONSISTENCY ANSWER:  0.38\n",
      "---- CONSISTENCY REASONING:  0.56\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "No successful runs for group ('Qwen3:0.6b', 'question_10.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.84\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.52\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.25\n",
      "---- CONSISTENCY REASONING:  0.6\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.5\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.44\n",
      "---- CONSISTENCY REASONING:  0.8\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.95\n",
      "No successful runs for group ('Qwen3:1.7b', 'question_05.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.8\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.84\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.85\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.96\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.3\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.89\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.6\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.92\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "No successful runs for group ('Qwen3:1.7b', 'question_10.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.8\n",
      "---- CONSISTENCY REASONING:  0.91\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.95\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.81\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.52\n",
      "---- CONSISTENCY ANSWER:  0.12\n",
      "---- CONSISTENCY REASONING:  0.8\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.4\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.2\n",
      "---- CONSISTENCY REASONING:  0.94\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.97\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  0.33\n",
      "---- CONSISTENCY REASONING:  0.42\n",
      "---- CONSISTENCY ANSWER:  0.88\n",
      "---- CONSISTENCY REASONING:  0.65\n",
      "---- CONSISTENCY ANSWER:  0.89\n",
      "---- CONSISTENCY REASONING:  0.77\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.51\n",
      "---- CONSISTENCY ANSWER:  0.5\n",
      "---- CONSISTENCY REASONING:  0.64\n",
      "---- CONSISTENCY ANSWER:  0.89\n",
      "---- CONSISTENCY REASONING:  0.78\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.8\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.48\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_01.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_02.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_02.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_02.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_03.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_03.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_03.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_03.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_04.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_04.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_05.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_05.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_05.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_05.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_06.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_06.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_06.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_07.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_07.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_07.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_08.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_09.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_09.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('TinyLlama:1.1b', 'question_10.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('smollm2:1.7b', 'question_01.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_01.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_01.txt', 'R4')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_02.txt', 'R1')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_02.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.98\n",
      "No successful runs for group ('smollm2:1.7b', 'question_03.txt', 'R1')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "No successful runs for group ('smollm2:1.7b', 'question_03.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_03.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('smollm2:1.7b', 'question_04.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_04.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_04.txt', 'R4')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "No successful runs for group ('smollm2:1.7b', 'question_05.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "---- CONSISTENCY ANSWER:  0.9\n",
      "---- CONSISTENCY REASONING:  0.99\n",
      "No successful runs for group ('smollm2:1.7b', 'question_06.txt', 'R1')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_06.txt', 'R2')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.83\n",
      "No successful runs for group ('smollm2:1.7b', 'question_06.txt', 'R4')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_07.txt', 'R1')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_07.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_07.txt', 'R3')\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  0.82\n",
      "---- CONSISTENCY ANSWER:  1.0\n",
      "---- CONSISTENCY REASONING:  1.0\n",
      "No successful runs for group ('smollm2:1.7b', 'question_08.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_08.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_08.txt', 'R4')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_09.txt', 'R1')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_09.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_09.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_09.txt', 'R4')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_10.txt', 'R1')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_10.txt', 'R2')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_10.txt', 'R3')\n",
      "No successful runs for group ('smollm2:1.7b', 'question_10.txt', 'R4')\n",
      "\n",
      "--- Determinism Results Table ---\n",
      "    Model Display Name    Question File Prompting Tech  Consistency Score  \\\n",
      "0     DeepSeek R1:1.5b  question_01.txt             R1               0.95   \n",
      "1     DeepSeek R1:1.5b  question_01.txt             R2               0.00   \n",
      "2     DeepSeek R1:1.5b  question_01.txt             R3               0.00   \n",
      "3     DeepSeek R1:1.5b  question_01.txt             R4               0.56   \n",
      "4     DeepSeek R1:1.5b  question_02.txt             R1               0.00   \n",
      "..                 ...              ...            ...                ...   \n",
      "475       smollm2:1.7b  question_09.txt             R4               0.00   \n",
      "476       smollm2:1.7b  question_10.txt             R1               0.00   \n",
      "477       smollm2:1.7b  question_10.txt             R2               0.00   \n",
      "478       smollm2:1.7b  question_10.txt             R3               0.00   \n",
      "479       smollm2:1.7b  question_10.txt             R4               0.00   \n",
      "\n",
      "     Answer Consistency  Reasoning Consistency  Number of Runs  \\\n",
      "0                   1.0                   0.82              10   \n",
      "1                   1.0                   0.82              10   \n",
      "2                   1.0                   0.82              10   \n",
      "3                   0.5                   0.69              10   \n",
      "4                   0.5                   0.69              10   \n",
      "..                  ...                    ...             ...   \n",
      "475                 1.0                   1.00              10   \n",
      "476                 1.0                   1.00              10   \n",
      "477                 1.0                   1.00              10   \n",
      "478                 1.0                   1.00              10   \n",
      "479                 1.0                   1.00              10   \n",
      "\n",
      "     Number of Failures  Number of Successful Runs  \\\n",
      "0                     9                          1   \n",
      "1                    10                          0   \n",
      "2                    10                          0   \n",
      "3                     8                          2   \n",
      "4                    10                          0   \n",
      "..                  ...                        ...   \n",
      "475                  10                          0   \n",
      "476                  10                          0   \n",
      "477                  10                          0   \n",
      "478                  10                          0   \n",
      "479                  10                          0   \n",
      "\n",
      "                                          Final Answer  \\\n",
      "0    [b, b, _FORMAT_FAILURE_, b, b, b, _FORMAT_FAIL...   \n",
      "1    [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "2                       [b, b, b, b, b, c, c, c, c, f]   \n",
      "3    [b, f, b, b, b, b, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "4        [_FORMAT_FAILURE_, d, d, d, d, d, d, b, d, d]   \n",
      "..                                                 ...   \n",
      "475                     [f, f, f, f, f, f, f, f, f, e]   \n",
      "476  [f, f, f, f, f, f, f, _FORMAT_FAILURE_, _FORMA...   \n",
      "477  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "478                     [f, f, f, f, f, f, f, f, f, f]   \n",
      "479                     [f, f, f, f, f, f, f, f, f, f]   \n",
      "\n",
      "                                             Reasoning  \\\n",
      "0    [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "1    [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "2    [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "3    [To convert 61 to binary: - Divide by 2: quoti...   \n",
      "4    [To convert the decimal number 61 to hexadecim...   \n",
      "..                                                 ...   \n",
      "475  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "476  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "477  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "478  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "479  [_FORMAT_FAILURE_, _FORMAT_FAILURE_, _FORMAT_F...   \n",
      "\n",
      "                                           All Answers  Determinism  \n",
      "0    [The binary representation of the decimal numb...         True  \n",
      "1    [_OVERTHINK_FAILURE_, _OVERTHINK_FAILURE_, _OV...        False  \n",
      "2    [The binary representation of the decimal numb...        False  \n",
      "3    [The binary representation of 61 is obtained b...        False  \n",
      "4    [The hexadecimal representation of the decimal...        False  \n",
      "..                                                 ...          ...  \n",
      "475  [[[ ## question ## ]] question  [[ ## thought ...        False  \n",
      "476  [[[ ## question ## ]] question  [[ ## thought ...        False  \n",
      "477  [[[ ## question ## ]] question: What is the su...        False  \n",
      "478  [[[ ## question ## ]] question: What is the su...        False  \n",
      "479  [[[ ## question ## ]] question: What is the su...        False  \n",
      "\n",
      "[480 rows x 13 columns]\n",
      "\n",
      "Determinism table saved to: ../../../data/determinism_tables/determinism_table_temp_00_mc_new.csv\n",
      "DataFrame loaded from ../../../data/determinism/opik_determinism_data_temp_00.csv with shape: (9600, 22)\n",
      "MODELS:  []\n",
      "\n",
      "Columns in Empty DataFrame\n",
      "Columns: [run_name, model_display_name, question_file, answer, correct_answer, prompting_tech, is_failure, reasoning, final_answer]\n",
      "Index: []:\n",
      "['run_name', 'model_display_name', 'question_file', 'answer', 'correct_answer', 'prompting_tech', 'is_failure', 'reasoning', 'final_answer']\n",
      "No determinism results found. The input DataFrame may be empty or not contain valid data.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Consistency Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m temp_00_oa_df = temp_00_df[temp_00_df[\u001b[33m'\u001b[39m\u001b[33mquestion_type\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mopen_answer\u001b[39m\u001b[33m'\u001b[39m].copy()\n\u001b[32m     10\u001b[39m output_filename = \u001b[33m\"\u001b[39m\u001b[33mdeterminism_table_temp_00_oa_new.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mgenerate_determinism_table_oa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_00_oa_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 557\u001b[39m, in \u001b[36mgenerate_determinism_table_oa\u001b[39m\u001b[34m(oa_df, filename)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMODELS: \u001b[39m\u001b[33m\"\u001b[39m, unique_models)\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Create CSV determinism table\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[43mcreate_determinism_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43moa_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 416\u001b[39m, in \u001b[36mcreate_determinism_table\u001b[39m\u001b[34m(df, filename)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Calculate consistency\u001b[39;00m\n\u001b[32m    414\u001b[39m consistency_df = calculate_consistency(df)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m determinism_df = \u001b[43mget_determinism\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsistency_df\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m#determinism_table = process_determinism_and_store(consistency_df, function)\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Determinism Results Table ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 396\u001b[39m, in \u001b[36mget_determinism\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_determinism\u001b[39m(df: pd.DataFrame) -> pd.DataFrame:\n\u001b[32m    395\u001b[39m     determinism_df = df.copy()\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     determinism_df[\u001b[33m'\u001b[39m\u001b[33mDeterminism\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdeterminism_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mConsistency Score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x >= \u001b[32m0.8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m determinism_df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLMmark/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLMmark/.venv/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Consistency Score'"
     ]
    }
   ],
   "source": [
    "# TEMPERATURE = 0.0\n",
    "csv_filename=\"opik_determinism_data_temp_00.csv\"\n",
    "temp_00_df = get_dataframe_from_csv(csv_filename=csv_filename)\n",
    "# Multiple choice answers\n",
    "output_filename = \"determinism_table_temp_00_mc_new.csv\"\n",
    "generate_determinism_table_mc(temp_00_df, filename=output_filename)\n",
    "# Open answer questions\n",
    "temp_00_oa_df = temp_00_df[temp_00_df['question_type'] == 'open_answer'].copy()\n",
    "output_filename = \"determinism_table_temp_00_oa_new.csv\"\n",
    "generate_determinism_table_oa(temp_00_oa_df, filename=output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
